{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pyreadr.read_r('../Daten/pw_lists/Badische Zeitung_links.RDS')\n",
    "#d2 = pyreadr.read_r('../Daten/pw_lists/Berliner Morgenpost_links.RDS')\n",
    "d2 = pyreadr.read_r('../Daten/pw_lists/Berliner Zeitung_links.RDS')\n",
    "d3 = pyreadr.read_r('../Daten/pw_lists/Bild_links.RDS')\n",
    "d4 = pyreadr.read_r('../Daten/pw_lists/Compact_links.RDS')\n",
    "d5 = pyreadr.read_r('../Daten/pw_lists/faz_links.RDS')\n",
    "d6 = pyreadr.read_r('../Daten/pw_lists/Hamburger MoPo_links.RDS')\n",
    "d7 = pyreadr.read_r('../Daten/pw_lists/Handelsblatt_links.RDS')\n",
    "d8 = pyreadr.read_r('../Daten/pw_lists/Jacobin_links.RDS')\n",
    "d9 = pyreadr.read_r('../Daten/pw_lists/Junge Freiheit_links.RDS')\n",
    "#d11 = pyreadr.read_r('../Daten/pw_lists/Junge Welt_links.RDS')\n",
    "d10 = pyreadr.read_r('../Daten/pw_lists/Jungle World_links.RDS')\n",
    "d11 = pyreadr.read_r('../Daten/pw_lists/KN_links.RDS')\n",
    "d12 = pyreadr.read_r('../Daten/pw_lists/LVZ_links.RDS')\n",
    "#d15 = pyreadr.read_r('../Daten/pw_lists/nordbayern.de_links.RDS_links.RDS')\n",
    "d13 = pyreadr.read_r('../Daten/pw_lists/Ostsee-Zeitung_links.RDS')\n",
    "d14 = pyreadr.read_r('../Daten/pw_lists/RND_links.RDS')\n",
    "d15 = pyreadr.read_r('../Daten/pw_lists/RP Online_links.RDS')\n",
    "d16 = pyreadr.read_r('../Daten/pw_lists/Spiegel_links.RDS')\n",
    "d17 = pyreadr.read_r('../Daten/pw_lists/Stuttgarter Zeitung_links.RDS')\n",
    "d18 = pyreadr.read_r('../Daten/pw_lists/SZ_links.RDS')\n",
    "#d22 = pyreadr.read_r('../Daten/pw_lists/TA_links.RDS')\n",
    "d19 = pyreadr.read_r('../Daten/pw_lists/Tagesspiegel_links.RDS')\n",
    "d20 = pyreadr.read_r('../Daten/pw_lists/Welt_links.RDS')\n",
    "\n",
    "d21 = pd.read_csv('../Daten/pw_lists/BM_file.csv')\n",
    "d22 = pd.read_csv('../Daten/pw_lists/JW_file.csv')\n",
    "d23 = pd.read_csv('../Daten/pw_lists/nb_file.csv')\n",
    "d24 = pd.read_csv('../Daten/pw_lists/TA.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [globals()[f'd{i}'] for i in range(1, 21)]\n",
    "modified_dataframes = [df[None] for df in dataframes]\n",
    "final_dataframe = pd.concat(modified_dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = final_dataframe[final_dataframe['paywalled'] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove whole rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 5)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = JWo[JWo['text'].str.contains(r'Noch kein Abonnement', case=False, regex=True)]\n",
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_remove = filtered['_id'].unique().tolist()\n",
    "JWo = JWo[~JWo['_id'].isin(ids_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count rows containig certain phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows mentioning 'ads': 0\n"
     ]
    }
   ],
   "source": [
    "pattern = r'Um diesen Inhalt zu lesen, wird ein Online-Abo benötigt' \n",
    "count = sum(JWo['text'].str.contains(pattern, regex=True, flags=re.IGNORECASE))\n",
    "\n",
    "print(\"Number of rows mentioning 'ads':\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove sections (before a certain phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_before_phrase(text, phrase='THEMEN'):\n",
    "    \"\"\"\n",
    "    Removes everything before and including a specific phrase in a text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "    - phrase (str): The phrase to search for. Everything before and including this phrase will be removed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The processed text with the specified content removed.\n",
    "    \"\"\"\n",
    "    pos = text.find(phrase)\n",
    "    if pos != -1:\n",
    "        return text[pos + len(phrase):].lstrip()\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Focus['text'] = Focus['text'].apply(lambda x: remove_before_phrase(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove sections (after a certain phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_topics_and_following(text):\n",
    "    \"\"\"\n",
    "    Removes the row that contains only 'topics' (case-insensitive) and everything that follows.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified text with 'topics' and subsequent content removed.\n",
    "    \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().lower() == 'Die Regierung will nicht, dass Sie das hier über die Euro-Situation lesen:':\n",
    "            return '\\n'.join(lines[:i])\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NP['text'] = NP['text'].apply(remove_topics_and_following)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specific_lines(text, phrase='Weiterlesen nach der Anzeige'):\n",
    "    \"\"\"\n",
    "    Removes lines from a text that start with a specific phrase.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "    - phrase (str): The phrase that, if a line starts with, will cause the line to be removed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The processed text with specific lines removed.\n",
    "    \"\"\"\n",
    "    lines = text.split('\\n')\n",
    "    filtered_lines = [line for line in lines if not line.lower().startswith(phrase.lower())]\n",
    "    return '\\n'.join(filtered_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "KN['text'] = KN['text'].apply(remove_specific_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_length_of_article(text):\n",
    "    \"\"\"\n",
    "    Removes the section starting with 'length of article:' up to the next double newline,\n",
    "    accounting for variations in how the text is structured.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with the specified sections removed.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'(?i)\\s*NRW\\s*.*?\\n\\n', flags=re.DOTALL)\n",
    "    return pattern.sub('', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_length_of_article(text):\n",
    "    \"\"\"\n",
    "    Removes the section starting with 'length of article:' up to the next double newline,\n",
    "    accounting for variations in how the text is structured.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with the specified sections removed.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'(?i)\\s*1 \\/ 1\\s*.*?slide 1 of 1', flags=re.DOTALL)\n",
    "    return pattern.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weser['text'] = Weser['text'].apply(remove_length_of_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_date_time_rows(text):\n",
    "    \"\"\"\n",
    "    Removes rows that contain only a date and time in the format 'dd.mm.yyyy, hh:mm Uhr'.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with date and time rows removed.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^\\d{1,2}\\.\\d{1,2}\\.\\d{4}, \\d{1,2}:\\d{2} Uhr', flags=re.MULTILINE)\n",
    "    \n",
    "    filtered_lines = [line for line in text.split('\\n') if not pattern.match(line)]\n",
    "    return '\\n'.join(filtered_lines)\n",
    "\n",
    "# r'^\\d{2}\\.\\d{2}\\.\\d{4}, \\d{2}:\\d{2} Uhr$'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAZ['text'] = WAZ['text'].apply(remove_date_time_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_date_time_rows(text):\n",
    "    \"\"\"\n",
    "    Removes rows that contain only a date and time in the format 'dd.mm.yyyy, hh:mm Uhr'.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to process.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text with date and time rows removed.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'^\\d{1,2}\\.\\d{1,2}\\.\\d{4}, \\d{1,2}:\\d{2}', flags=re.MULTILINE)\n",
    "    \n",
    "    filtered_lines = [line for line in text.split('\\n') if not pattern.match(line)]\n",
    "    return '\\n'.join(filtered_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
