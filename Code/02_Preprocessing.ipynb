{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 02:20:04.769 Python[94867:5464411] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in News Outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mainstream national\n",
    "Bild = pd.read_csv('../Outlets/Bild.csv')\n",
    "FAZ = pd.read_csv('../Outlets/FAZ.csv')\n",
    "Focus = pd.read_csv('../Outlets/Focus.csv')\n",
    "HB = pd.read_csv('../Outlets/HB.csv')\n",
    "Heute = pd.read_csv('../Outlets/Heute.csv')\n",
    "NTV = pd.read_csv('../Outlets/NTV.csv')\n",
    "RND = pd.read_csv('../Outlets/RND.csv')\n",
    "Spiegel = pd.read_csv('../Outlets/Spiegel.csv')\n",
    "Tagesschau = pd.read_csv('../Outlets/Tagesschau.csv')\n",
    "TAZ = pd.read_csv('../Outlets/TAZ.csv')\n",
    "Vice = pd.read_csv('../Outlets/Vice.csv')\n",
    "Welt = pd.read_csv('../Outlets/Welt.csv')\n",
    "SZ = pd.read_csv('../Outlets/SZ.csv')\n",
    "\n",
    "#Regional media\n",
    "AZ = pd.read_csv('../Outlets/AZ.csv')\n",
    "BaZ = pd.read_csv('../Outlets/BaZ.csv')\n",
    "BM = pd.read_csv('../Outlets/BM.csv')\n",
    "BeZ = pd.read_csv('../Outlets/BeZ.csv')\n",
    "HM = pd.read_csv('../Outlets/HM.csv')\n",
    "HAZ = pd.read_csv('../Outlets/HAZ.csv')\n",
    "HNA = pd.read_csv('../Outlets/HNA.csv')\n",
    "LVZ = pd.read_csv('../Outlets/LVZ.csv')\n",
    "Merkur = pd.read_csv('../Outlets/Merkur.csv')\n",
    "NB = pd.read_csv('../Outlets/NB.csv')\n",
    "NK = pd.read_csv('../Outlets/NK.csv')\n",
    "OZ = pd.read_csv('../Outlets/OZ.csv')\n",
    "RP = pd.read_csv('../Outlets/RP.csv')\n",
    "StZ = pd.read_csv('../Outlets/SZ.csv')\n",
    "TA = pd.read_csv('../Outlets/TA.csv')\n",
    "Tag24 = pd.read_csv('../Outlets/Tag24.csv')\n",
    "WAZ = pd.read_csv('../Outlets/WAZ.csv')\n",
    "Weser = pd.read_csv('../Outlets/Weser.csv')\n",
    "\n",
    "#Alternative right\n",
    "AdG = pd.read_csv('../Outlets/AdG.csv')\n",
    "Compact = pd.read_csv('../Outlets/Compact.csv')\n",
    "DU = pd.read_csv('../Outlets/DU.csv')\n",
    "ET = pd.read_csv('../Outlets/ET.csv')\n",
    "FW = pd.read_csv('../Outlets/FW.csv')\n",
    "Jouwatch = pd.read_csv('../Outlets/Jouwatch.csv')\n",
    "JF = pd.read_csv('../Outlets/JF.csv')\n",
    "MMnews = pd.read_csv('../Outlets/Mmnews.csv')\n",
    "NP = pd.read_csv('../Outlets/NP.csv')\n",
    "O24 = pd.read_csv('../Outlets/O24.csv')\n",
    "PI = pd.read_csv('../Outlets/PI.csv')\n",
    "PTV = pd.read_csv('../Outlets/PTV.csv')\n",
    "TE = pd.read_csv('../Outlets/TE.csv')\n",
    "Zuerst = pd.read_csv('../Outlets/Zuerst.csv')\n",
    "\n",
    "# #Alternative left\n",
    "Jacobin = pd.read_csv('../Outlets/Jacobin.csv')\n",
    "JWe = pd.read_csv('../Outlets/JWe.csv')\n",
    "JWo = pd.read_csv('../Outlets/JWo.csv')\n",
    "KgK = pd.read_csv('../Outlets/KgK.csv')\n",
    "KN = pd.read_csv('../Outlets/KN.csv')\n",
    "ND = pd.read_csv('../Outlets/ND.csv')\n",
    "RG = pd.read_csv('../Outlets/RG.csv')\n",
    "TP = pd.read_csv('../Outlets/TP.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "national = pd.concat([Bild, FAZ, Focus, HB, Heute, NTV, RND, Spiegel, Tagesschau, TAZ, Vice, Welt, SZ])\n",
    "regional = pd.concat([AZ, BaZ, BM, BeZ, HM, HAZ, HNA, LVZ, Merkur, NB, NK, OZ, RP, StZ, TA, Tag24, WAZ, Weser])\n",
    "right = pd.concat([AdG, Compact, DU, ET, FW, Jouwatch, JF, MMnews, NP, O24, PI, PTV, TE, Zuerst])\n",
    "left = pd.concat([Jacobin, JWe, JWo, KgK, KN, ND, RG, TP])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "national['outlet']='national'\n",
    "regional['outlet']='regional'\n",
    "right['outlet']='right'\n",
    "left['outlet']='left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([national, regional, right, left])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step was completed iteratively in order to remove all articles that had already been processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "somalia = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1681736, 7)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_remove1 = somalia_masked['_id'].unique().tolist()\n",
    "ids_to_remove2 = afghanistan_masked['_id'].unique().tolist()\n",
    "ids_to_remove3 = syrien_masked['_id'].unique().tolist()\n",
    "ids_to_remove4 = türkei_masked['_id'].unique().tolist()\n",
    "ids_to_remove5 = ukraine_masked['_id'].unique().tolist()\n",
    "ids_to_remove6 = flüchtling_masked['_id'].unique().tolist()\n",
    "ids_to_remove= ids_to_remove1 + ids_to_remove2 + ids_to_remove3 + ids_to_remove4 +ids_to_remove5 + ids_to_remove6 \n",
    "\n",
    "\n",
    "migrant = df.copy()\n",
    "migrant = migrant[~migrant['_id'].isin(ids_to_remove)]\n",
    "\n",
    "migrant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular expression pattern\n",
    "ukr = r'\\b(ukraine(?:r|rs|rn|rin|rinnen))\\b'\n",
    "tur = r'\\b(türk(?:e|en|in|innen))\\b'\n",
    "syr = r'\\b(syre(?:r|rs|rn|rin|rinnen))\\b'\n",
    "som = r'\\b(somalie(?:r|rs|rn|rin|rinnen))\\b'\n",
    "afg = r'\\b(afghan(?:e|en|in|innen))\\b'\n",
    "flu = r'(\\b(?:flüchtling(?:s|e|en|en)?|geflüchtete(?:r|n)?)\\b)'\n",
    "mig = r'\\b(migrant(?:en|in|innen)?|immigrant(?:en|in|innen)?|einwander(?:er|ers|ern|in|innen)?|zuwander(?:er|ers|ern|in|innen)?)\\b'\n",
    "\n",
    "pattern = ukr\n",
    "matches = df['text'].str.extractall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "#get unique matches\n",
    "for col in matches:\n",
    "    uniquematch = matches[0].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(uniquematch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sections with matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\b(migrant(?:en|in|innen)?|immigrant(?:en|in|innen)?|einwander(?:er|ers|ern|in|innen)?|zuwander(?:er|ers|ern|in|innen)?)\\b\n"
     ]
    }
   ],
   "source": [
    "def extract_sections(article):\n",
    "    \"\"\" \n",
    "    1. splits the articles into sections\n",
    "    2. extracts sections based on the pattern defined in the previous cell\n",
    "    3. when a section is extracted and it is shorter or equals 3 sentences then the previous section if there is one and it hasn't been \n",
    "    extracted already otherwise it'll extract the next section \n",
    "    \"\"\"\n",
    "    # Compile the regular expression pattern\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    # Split the article into sections based on two newline characters\n",
    "    sections = article.split('\\n\\n')\n",
    "    \n",
    "    # Keep track of which sections have been extracted\n",
    "    extracted_flags = [False] * len(sections)\n",
    "    \n",
    "    extracted_groups = []\n",
    "    for i, section in enumerate(sections):\n",
    "        if not extracted_flags[i] and compiled_pattern.search(section):\n",
    "            current_group = []\n",
    "            sentences = sent_tokenize(section, language='german')\n",
    "            num_sentences = len(sentences)\n",
    "            if num_sentences >= 3:\n",
    "                current_group.append(section)\n",
    "                extracted_flags[i] = True\n",
    "            else:\n",
    "                # Extract the previous section if it exists and hasn't been extracted\n",
    "                if i > 0 and not extracted_flags[i-1]:\n",
    "                    current_group.append(sections[i-1])\n",
    "                    extracted_flags[i-1] = True\n",
    "                current_group.append(section)\n",
    "                extracted_flags[i] = True\n",
    "                # Extract the next section if it exists and hasn't been extracted\n",
    "                if i < len(sections)-1 and not extracted_flags[i+1]:\n",
    "                    current_group.append(sections[i+1])\n",
    "                    extracted_flags[i+1] = True\n",
    "            if current_group:\n",
    "                extracted_groups.append(current_group)\n",
    "    return extracted_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant['sections_with_keyword'] = migrant['text'].apply(lambda x: extract_sections(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_to_strings(list_of_lists):\n",
    "    \"\"\" \n",
    "    the extracted lists are being joined to a list\n",
    "    \"\"\"\n",
    "    return [' '.join(sublist) for sublist in list_of_lists]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant['sections'] = migrant['sections_with_keyword'].apply(flatten_to_strings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sections with matches and drop unneccesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant = migrant[migrant['sections'].apply(lambda x: len(x) > 0)]\n",
    "migrant_masked = migrant[['_id', 'sections', 'outlet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ukrainer']\n"
     ]
    }
   ],
   "source": [
    "def replace_words(text_list, words_to_replace, replacement_word):\n",
    "    new_text_list = []\n",
    "    for text in text_list:\n",
    "        for old_word in words_to_replace:\n",
    "            # Using regular expression to match whole words\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(old_word))\n",
    "            text = re.sub(pattern, replacement_word, text, flags=re.IGNORECASE)\n",
    "        new_text_list.append(text)\n",
    "    return new_text_list\n",
    "\n",
    "words_to_replace = uniquematch\n",
    "replacement_word = \"[Zielgruppe]\"\n",
    "print(uniquematch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['masked'] = df['response'].apply(lambda x: replace_words(x, words_to_replace, replacement_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode masked column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant_masked = migrant_masked.explode('masked')\n",
    "#Reset index\n",
    "migrant_masked.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for more Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_ukraine = '[Zielgruppe]'\n",
    "re_türkei = '[Gruppe2]'\n",
    "re_syrien = '[Gruppe3]'\n",
    "re_somalien = '[Gruppe4]'\n",
    "re_afghanistan = '[Gruppe5]'\n",
    "re_flüchtling = '[Gruppe6]'\n",
    "re_einwanderer = '[Gruppe6]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ukr_pattern = r'\\b\\w*ukraine\\w*\\b' #\n",
    "ukr1_pattern = r'\\b\\w*ukrainisch\\w*\\b' #\n",
    "tur_pattern = r'\\b\\w*türkei\\w*\\b' #\n",
    "tur1_pattern = r'\\b\\w*türki\\w*\\b' #\n",
    "syr_pattern = r'\\b\\w*syrer\\w*\\b' \n",
    "syr1_pattern = r'\\b\\w*syri\\w*\\b' #\n",
    "som_pattern = r'\\b\\w*somali\\w*\\b' \n",
    "afg_pattern = r'\\b\\w*afghan\\w*\\b'\n",
    "fl_pattern = r'\\b\\w*flüchtl\\w*\\b' #\n",
    "fl1_pattern = r'\\w*geflücht\\w*\\b'\n",
    "ein_pattern = r'\\w*einwanderer\\w*\\b'\n",
    "ein1_pattern = r'\\w*zuwanderer\\w*\\b'\n",
    "ein2_pattern = r'\\w*immigrant\\w*\\b'\n",
    "ein3_pattern = r'\\w*migrant\\w*\\b'\n",
    "\n",
    "\n",
    "\n",
    "patterns = [ukr_pattern, ukr1_pattern, tur_pattern, tur1_pattern, syr_pattern, syr1_pattern, som_pattern, afg_pattern, fl_pattern, fl1_pattern, ein_pattern, ein1_pattern, ein2_pattern, ein3_pattern]\n",
    "\n",
    "# Function to find which patterns are found in the text\n",
    "def find_patterns(text, patterns):\n",
    "    found_patterns = set()  \n",
    "    for pattern in patterns:\n",
    "        if re.findall(pattern, text,re.IGNORECASE):\n",
    "            found_patterns.add(pattern)\n",
    "    return found_patterns\n",
    "\n",
    "all_found_patterns = set()\n",
    "\n",
    "# Iterate over each row in the DataFrame column and update the set of found patterns\n",
    "for t in df['masked']:\n",
    "    all_found_patterns.update(find_patterns(t, patterns))\n",
    "\n",
    "# Convert the set to a list \n",
    "all_found_patterns_list = list(all_found_patterns)\n",
    "print(all_found_patterns_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_ukraine_special)\n",
    "data['masked'] = data['text'].apply(replace_ukrainisch_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_türkisch_special)\n",
    "data['masked'] = data['text'].apply(replace_türke_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_syrien_special)\n",
    "data['masked'] = data['text'].apply(replace_syrisch_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_somalisch_special)\n",
    "data['masked'] = data['text'].apply(replace_somali_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_afghanistan_special)\n",
    "data['masked'] = data['text'].apply(replace_afghanisch_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_flüchtl_special)\n",
    "data['masked'] = data['text'].apply(replace_geflüchte_special)\n",
    "\n",
    "data['masked'] = data['text'].apply(replace_migrant_special)\n",
    "data['masked'] = data['text'].apply(replace_einwa_special)\n",
    "data['masked'] = data['text'].apply(replace_zuwan_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_migrant_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'migrant(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_einwa_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'einwanderer(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1) \n",
    "        \n",
    "    \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_zuwan_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'zuwanderer(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1) \n",
    "        \n",
    "    \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_flüchtl_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'flüchtling(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1) \n",
    "    \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_flüchtling\n",
    "        else: \n",
    "            return re_flüchtling + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_geflüchte_special(text, exclude_sequences=['t']):\n",
    "    pattern = r'(?<!hin)Geflüchte(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        \n",
    "    \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2: \n",
    "            return re_flüchtling\n",
    "        else:  \n",
    "            return re_flüchtling + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_afghanistan_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'afghanistan(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2: \n",
    "            return re_afghanistan\n",
    "        else: \n",
    "            return re_afghanistan + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_afghanisch_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'afghanisch(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_afghanistan\n",
    "        else:  \n",
    "            return re_afghanistan + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_somalisch_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'somalisch(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_somalien\n",
    "        else: \n",
    "            return re_somalien + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_somali_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'somali(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2: \n",
    "            return re_somalien\n",
    "        else:  \n",
    "            return re_somalien + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_syrien_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'syri(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_syrien\n",
    "        else:  \n",
    "            return re_syrien + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_syrisch_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'(?<!weiß)(?<!bela)syrisch(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 2:  \n",
    "            return re_syrien\n",
    "        else:  \n",
    "            return re_syrien + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_türke_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'(?<!bela)türke(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 5:  \n",
    "            return re_türkei\n",
    "        else:  \n",
    "            return re_türkei + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_türkisch_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'(?<!bela)türki(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 5:  \n",
    "            return re_türkei\n",
    "        else: \n",
    "            return re_türkei + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ukraine_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'(?<!weiß)(?<!bela)ukraine(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 5: \n",
    "            return re_ukraine\n",
    "        else:  \n",
    "            return re_ukraine + following_chars\n",
    "    \n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_ukrainisch_special(text, exclude_sequences=['abc']):\n",
    "    pattern = r'(?<!weiß)(?<!bela)ukrainisch(\\w*)\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        following_chars = match.group(1)  \n",
    "        if following_chars.lower() in exclude_sequences:\n",
    "            return match.group(0)\n",
    "        \n",
    "        if len(following_chars) <= 5:  \n",
    "            return re_ukraine\n",
    "        else:  \n",
    "            return re_ukraine + following_chars\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['masked'] = data['masked'].apply(replace_ukraine)\n",
    "data['masked'] = data['masked'].apply(replace_ukrainisch)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_türkei)\n",
    "data['masked'] = data['masked'].apply(replace_türkisch)\n",
    "data['masked'] = data['masked'].apply(replace_türke)\n",
    "data['masked'] = data['masked'].apply(replace_türkin)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_syrien)\n",
    "data['masked'] = data['masked'].apply(replace_syrisch)\n",
    "data['masked'] = data['masked'].apply(replace_syrer)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_somalia)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_afghanistan)\n",
    "data['masked'] = data['masked'].apply(replace_afghanisch)\n",
    "data['masked'] = data['masked'].apply(replace_afghane)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_flüchtling)\n",
    "data['masked'] = data['masked'].apply(replace_geflüchtete)\n",
    "\n",
    "data['masked'] = data['masked'].apply(replace_einwanderer)\n",
    "data['masked'] = data['masked'].apply(replace_einwanderin)\n",
    "data['masked'] = data['masked'].apply(replace_migrant)\n",
    "data['masked'] = data['masked'].apply(replace_immigrant)\n",
    "data['masked'] = data['masked'].apply(replace_zuwanderer)\n",
    "data['masked'] = data['masked'].apply(replace_zuwanderin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Ukraine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ukraine(text):\n",
    "    pattern = r'ukraine([a-zA-Z]{0,3})\\b|ukraine(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1): \n",
    "            return re_ukraine\n",
    "        else:  \n",
    "            return re_ukraine + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_ukrainisch(text):\n",
    "    pattern = r'ukrainisch(\\w{0,2})\\b|ukrainisch(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1): \n",
    "            return re_ukraine\n",
    "        else:  \n",
    "            return re_ukraine + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Türkei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_türkei(text):\n",
    "    pattern = r'\\bTürkei([a-zA-Z]{0,1})\\b|\\bTürkei(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_türkei\n",
    "        else:  \n",
    "            return re_türkei + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_türkisch(text):\n",
    "    pattern = r'\\bTürkisch(\\w{0,2})\\b|\\bTürkisch(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_türkei\n",
    "        else:  \n",
    "            return re_türkei + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_türke(text):\n",
    "    pattern = r'\\bTürke(\\w{0,2})\\b|\\bTürki(\\w*)|\\bTürken(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_türkei\n",
    "        else:  \n",
    "            return re_türkei + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_türkin(text):\n",
    "    pattern = r'\\bTürki(\\w{0,2})\\b|\\bTürkin(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_türkei\n",
    "        else: \n",
    "            return re_türkei + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Syrien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_syrien(text):\n",
    "    pattern = r'syrien(\\w{0,2})\\b|syrien(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1): \n",
    "            return re_syrien\n",
    "        else:  \n",
    "            return re_syrien + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_syrisch(text):\n",
    "    pattern = r'syrisch(\\w{0,2})\\b|syrisch(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_syrien\n",
    "        else:  \n",
    "            return re_syrien + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_syrer(text):\n",
    "    pattern = r'syrer(\\w{0,5})\\b|syrer(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_syrien\n",
    "        else:  \n",
    "            return re_syrien + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Somalia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_somalia(text):\n",
    "    pattern = r'somali(\\w*)'\n",
    "    def replace(match):\n",
    "        if match.group():  \n",
    "            return re_somalien\n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Afghansitan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_afghanistan(text):\n",
    "    pattern = r'\\bAfghanistan(\\w{0,2})\\b|\\bAfghanistan(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_afghanistan\n",
    "        else:  \n",
    "            return re_afghanistan + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_afghanisch(text):\n",
    "    pattern = r'afghanisch(\\w{0,2})\\b|afghanisch(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_afghanistan\n",
    "        else:  \n",
    "            return re_afghanistan + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_afghane(text):\n",
    "    pattern = r'\\bafghan(\\w*)'\n",
    "    def replace(match):\n",
    "        if match.group(): \n",
    "            return re_afghanistan\n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Flüchtlinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_flüchtling(text):\n",
    "    pattern = r'flüchtling([a-zA-Z]{0,2})\\b|flüchtlings(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_flüchtling\n",
    "        else:  \n",
    "            return re_flüchtling + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_geflüchtete(text):\n",
    "    pattern = r'\\bgeflüchtete([a-zA-Z]{0,2})\\b|\\bgeflüchtete(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_flüchtling\n",
    "        else:  \n",
    "            return re_flüchtling + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove more matches (Migr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_migrant(text):\n",
    "    pattern = r'\\bmigrant([a-zA-Z]{0,5})\\b|\\bmigrant(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_immigrant(text):\n",
    "    pattern = r'\\bimmigrant([a-zA-Z]{0,5})\\b|\\bimmigrant(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else: \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_einwanderer(text):\n",
    "    pattern = r'einwanderer([a-zA-Z]{0,1})\\b|einwanderer(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_einwanderin(text):\n",
    "    pattern = r'\\beinwanderin([a-zA-Z]{0,3})\\b|\\beinwanderin(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_zuwanderer(text):\n",
    "    pattern = r'\\bzuwanderer([a-zA-Z]{0,1})\\b|\\bzuwanderer(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_zuwanderin(text):\n",
    "    pattern = r'\\bzuwandererin([a-zA-Z]{0,3})\\b|\\bzuwandererin(\\w*)'\n",
    "    \n",
    "    def replace(match):\n",
    "        if match.group(1):  \n",
    "            return re_einwanderer\n",
    "        else:  \n",
    "            return re_einwanderer + (match.group(2) if match.group(2) else '')\n",
    "    \n",
    "    return re.sub(pattern, replace, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapping of keywords to labels\n",
    "keyword_label_mapping = {\n",
    "    '[Gruppe2]': 'Somalia',\n",
    "    '[Gruppe7]': 'Afghanistan',\n",
    "    '[Gruppe4]': 'Flüchtlinge',\n",
    "    '[Gruppe1]': 'Migranten',\n",
    "    '[Gruppe3]': 'Ukraine',\n",
    "    '[Gruppe5]': 'Türkei',\n",
    "    '[Gruppe6]': 'Syrien',\n",
    "\n",
    "}\n",
    "\n",
    "def get_labels(text):\n",
    "    labels = []\n",
    "    for keyword, label in keyword_label_mapping.items():\n",
    "        if keyword in text:\n",
    "            labels.append(label)\n",
    "    return ', '.join(labels) if labels else 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant_masked['labels'] = migrant_masked['masked'].apply(get_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrant_masked.to_csv('../Masked Data/migrant_masked.csv')\n",
    "migrant.to_csv('../ExtractedData/migrant.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
